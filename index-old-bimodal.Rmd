--- 
title: "Workshop 2: calibrating a model with stochasticity and/or bimodality"
author: "Danny Scarponi, Andy Iskauskas"
site: bookdown::bookdown_site
output:
    bookdown::pdf_book:
        includes:
            in_header: header.tex
    bookdown::gitbook:
        config:
            sharing: null
        css: 'style.css'
        highlight: tango
        includes:
            in_header: _toggle.html
        keep_md: TRUE
bibliography: references.bib  
linkcolor: blue
documentclass: book
link-citations: yes
description: "An interactive introduction to the hmer package"
---

```{r, child = "_setup.Rmd", include = F, purl = F, cache = T}
```


```{r setup, include=F}
knitr::opts_chunk$set(echo = TRUE, cache =T)
chosen_params <- list(b = 1/(76*365), mu = 1/(76*365), beta1 = 0.214, beta2 = 0.107, beta3 = 0.428, lambda = 1/7, alpha = 1/50, gamma = 1/14, omega = 1/365)
library(hmer)
library(lhs)
library(deSolve)
library(ggplot2)
library(reshape2)
library(purrr)
library(tidyverse)
set.seed(123)
############################# HELPER FUNCTIONS #############################
# Gillespie algorithm implementation
# N is a list containing N$M, the initial number of people in each compartment (comprising deaths), N$Post, N$Pre, N$h, T is the
# time up to which we want to simulate (400th day by default). The while loop is there to "record" only the wanted times: for 
# example, if dt=1, then we want to record only the state of the system at t=0,1,2,3,4,5,... and if the rexp(1,h0) is not enough
# to send us to the next integer time, then we will do more than one cycle and record the state only when we reach the next 
# integer time.
gillespied=function (N, T=400, dt=1, ...)
{
  tt=0
  n=T%/%dt
  x=N$M
  S=t(N$Post-N$Pre)
  u=nrow(S)
  v=ncol(S)
  xmat=matrix(0,ncol=u,nrow=n)
  i=1
  target=0
  repeat {
    h=N$h(x, tt, ...)
    h0=sum(h)
    if (h0<1e-10)
      tt=1e99
    else
      tt=tt+rexp(1,h0)
    while (tt>=target) {
      xmat[i,]=x
      i=i+1
      target=target+dt
      if (i>n)
        #			        return(ts(xmat,start=0,deltat=dt))
        return(xmat)
    }
    j=sample(v,1,prob=h)
    x=x+S[,j]
  }
}

# Initial setup: transition matrices, hazard function, and initial conditions
Num <- 1000
N=list()
N$M=c(900,100,0,0,0)
# N$Pre=matrix(c(1,0,1,1,0,1),ncol=2,byrow=TRUE)
# N$Post=matrix(c(2,0,0,2,0,0),ncol=2,byrow=TRUE)
# Columns of N$Pre are 5, for S, E, I, R, and Deaths. Rows are for transitions: births, S to E, S to D, E to I, E to D, I to D,
# I to R, R to S, R to D. For example: the first row is all of zeros, since we need no person in S, nor in the other compartments 
# for a new birth to happen. 
# Columns of N$Post are 5 as for N$Pre. Rows are for transitions as for N$Pre. For example: the element in (1,1) is 1 since a new 
# birth goes straight into the S compartment. 
N$Pre = matrix(c(0,0,0,0,0,
                 1,0,0,0,0,
                 1,0,0,0,0,
                 0,1,0,0,0,
                 0,1,0,0,0,
                 0,0,1,0,0,
                 0,0,1,0,0,
                 0,0,0,1,0,
                 0,0,0,1,0), ncol = 5, byrow = TRUE)
N$Post = matrix(c(1,0,0,0,0,
                  0,1,0,0,0,
                  0,0,0,0,1,
                  0,0,1,0,0,
                  0,0,0,0,1,
                  0,0,0,0,1,
                  0,0,0,1,0,
                  1,0,0,0,0,
                  0,0,0,0,1), ncol = 5, byrow = TRUE)
# N$Pre=matrix(c(1,0,0,0,1,0,1,0,0),ncol=3,byrow=TRUE)
# N$Post=matrix(c(0,1,0,0,0,1,0,0,1),ncol=3,byrow=TRUE)
# Here x is the vector with the number of people in each of the compartments (deaths excluded), t is the time and th is a vector
# with the parameters. N$h return a vector with all the transition rates at time t.
N$h=function(x,t,th=rep(1,9))
{
  Num = x[1]+x[2]+x[3]+x[4]
  if (t > 270) tns <- th[5]
  else if (t > 180) tns <- (th[5]-th[4])*t/90+3*th[4]-2*th[5]
  else if (t > 100) tns <- th[4]
  else tns <- (th[4]-th[3])*t/100+th[3]
  return(
    c(th[1]*Num,
      tns*x[3]*x[1]/Num,
      th[2]*x[1],
      th[6]*x[2],
      th[2]*x[2],
      (th[7]+th[2])*x[3],
      th[8]*x[3],
      th[9]*x[4],
      th[2]*x[4])
  )
}

get_results <- function(params, nreps = 100, outs, times, raw = FALSE) {
  tseq <- 0:max(times)
  arra <- array(0, dim = c(max(tseq)+1, 5, nreps))
  for(i in 1:nreps) arra[,,i] <- gillespied(N,T=max(times) + 1 + 0.001,dt=1,th=params)
  if(raw) return(arra)
  collected <- list()
  for (i in 1:nreps) {
    relev <- c(arra[times+1, which(c("S", "E", "I", "R", "D") %in% outs), i])
    names <- unlist(purrr::map(outs, ~paste0(., times, sep = "")))
    relev <- setNames(relev, names)
    collected[[i]] <- relev
  }
  input_dat <- setNames(data.frame(matrix(rep(params, nreps), ncol = length(params), byrow = TRUE)), names(params))
  return(cbind(input_dat, do.call('rbind', collected)))
}

```

# Objectives
In this workshop, you will learn to perform history matching with emulation on models with stochasticity and/or bimodality, using the [hmer](https://github.com/Tandethsquire/hmer) package. This workshop should be addressed after working on [Workshop 1](https://danny-sc.github.io/determ_workshop/index.html), which shows how to perform history matching with emulation on deterministic models. 

# Introduction to the model {#intro}
In this section we introduce the model that we will work with throughout our workshop. To facilitate the comparison between the deterministic and the stochastic setting, we will work with the <span class="abbr" title="A model consisting of four compartments 

- $S$: Susceptible individuals,
- $E$: Exposed individuals (i.e. people that are infected but not infectious yet), 
- $I$: Infectious individuals,  
- $R$: Recovered individuals, 

and four possible transitions

- $S \rightarrow E$, when a susceptible individual becomes infected, 
- $E \rightarrow I$, when an infected individual becomes infectious,
- $I \rightarrow R$, when an infectious individual recovers,
- $R \rightarrow S$, when a recovered individual becomes susceptible again.

SEIRS models are used to study those infectious diseases that do not confer permanent immunity."><abbr title="A model consisting of four compartments 

- S: Susceptible individuals,
- E: Exposed individuals (i.e. people that are infected but not infectious yet), 
- I: Infectious individuals,  
- R: Recovered individuals, 

and four possible transitions

- S to E, when a susceptible individual becomes infected, 
- E to I, when an infected individual becomes infectious,
- I to R, when an infectious individual recovers,
- R to S, when a recovered individual becomes susceptible again.

SEIRS models are suitable to study those infectious diseases that have an incubation period and do not confer permanent immunity.">
SEIRS</abbr></span>
model which we used in [Workshop 1](https://danny-sc.github.io/determ_workshop/index.html), but this time we introduce stochasticity. The deterministic SEIRS model used in [Workshop 1](https://danny-sc.github.io/determ_workshop/index.html) was described by the following differential equations:

\begin{align}
\frac{dS}{dt} &= b N - \frac{\beta(t)IS}{N} + \omega R -\mu S  \\ 
\frac{dE}{dt} &= \frac{\beta(t)IS}{N} - \lambda E - \mu E \\ 
\frac{dI}{dt} &= \lambda E - \gamma I - (\mu + \alpha) I \\ 
\frac{dR}{dt} &= \gamma I - \omega R - \mu R
\end{align}

where $N$ is the total population, varying over time, and the parameters are as follows:

- $b$ is the birth rate, 

- $\mu$ is the  rate of death from other causes, 

- $\beta(t)$ is the infection rate between each infectious and susceptible individual, 

- $\sigma$ is the rate of becoming infectious after infection, 

- $\alpha$ is the rate of death from the disease, 

- $\gamma$ is the recovery rate and  

- $\omega$ is the rate at which immunity is lost following recovery. 

``` {r, echo = FALSE, fig.cap='SEIRS Diagram'}
knitr::include_graphics('SEIRSdiagram.png')
```

In order to obtain the solutions of the stochastic SEIR model for a given set of parameters, we will use a helper function, `get_results` (which is defined in the R-script). This function assumes an initial population of 900 susceptible individuals, 100 exposed individuals, and no infectious or recovered individuals, and uses the Gillespie algorithm to generate statistically correct trajectories of the model. The minimum specifications for this function are: the parameter set(s) to run the model on, a set of outputs (e.g. `c("S","R")`), and a set of times (e.g. `c(10,100,150)`) that we are interested in. The default behaviour of `get_results` is to run the model 100 times on the parameter set(s) provided, but more or less repetitions can be obtained, using the argument `nreps`. The function `get_results` returns a dataframe containing a row for each repetition at each parameter set provided, with the first nine columns showing the values of the parameters and the subsequent columns showing the requested outputs at the requested times. If `raw` is set to `TRUE`, all outputs and all times are instead returned: this is useful if we want to plot "continuous" trajectories.

As done in Workshop 1, the parameter set

```{r}
chosen_params <- c(
  b = 1/(76*365),
  mu = 1/(76*365),
  beta1 = 0.214, beta2 = 0.107, beta3 = 0.428,
  sigma = 1/7,
  alpha = 1/50,
  gamma = 1/14,
  omega = 1/365
)
```

will be used to define the target bounds for our calibration task. 

Using `get_results` on `chosen_params` 

```{r, fig.height=7, fig.width=7}
solution <- get_results(chosen_params, outs = c("I", "R"), 
                        times = c(25, 40, 100, 200, 300, 350, 500), raw = TRUE)
```

we get a 3-dimensional array `solution` such that `solution[t,j,i]` contains the number of individuals in the j-th compartment at time $t$ for the i-th run of the model at `chosen_params`. In particular, $t$ can take values $1,2,...,501$, $j$ can take values $1,2,3,4,5$ corresponding to $S, E, I, R, D$ (where $D$ stands for the number of deaths occurred), and $i$ can be $1,2,3,...,100$. 

Plotting the results for "I" and "R", we have

```{r, fig.height=7, fig.width=7}
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, solution[,j,i], col=(3:4)[j-2], lwd=0.3)
legend('topleft', legend = c('Infected', "Recovered"), lty = 1, 
       col = c(3,4), inset = c(0.05, 0.05))
```

The plot above clearly shows the stochasticty of our model. It also highlights that bimodality starts to appear in the number of recovered people around time $t=250$. The same also happens to the number of infected individuals, even if it is less evident from the graph: from time $t=250$ on, there is a large number of trajectories in green that have zero infected individuals (note the horizontal green line). Note that we've plotted trajectories up to $t=500$ to demonstrate the bimodality, but we won't match to targets for this time, in order to
maintain parity with the deterministic case.

Plotting the results for "S" also shows bimodality:

```{r, fig.height=7, fig.width=7}
plot(0:500, ylim=c(0,1000), ty="n", xlab = "Time", ylab = "Number", main = "Susceptibles")
for(i in 1:100) lines(0:500, solution[,1,i], col='black', lwd=0.3, 
                      xlab = "Time", ylab = "Number", main = "Susceptibles")
```

```{r, rtip1, eval = FALSE, echo = FALSE}
Copy the code below, modify the value of (some) parameters and run it.

``{r, eval = FALSE}
example_params <- c(
  b = 1/(76*365),
  mu = 1/(76*365),
  beta1 = 0.214, beta2 = 0.107, beta3 = 0.428,
  sigma = 1/7,
  alpha = 1/50,
  gamma = 1/14,
  omega = 1/365
)
solution <- get_results(example_params, outs = c("I", "R"), 
                        times = c(25, 40, 100, 200, 300, 350, 500), raw = TRUE)
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, solution[,j,i], col=(3:4)[j-2], lwd=0.3)
legend('topleft', legend = c('Infected', "Recovered"), lty = 1, 
       col = c(3,4), inset = c(0.05, 0.05))
``

```

```{task}
If you would like, familiarise yourself with the model. Investigate how the plots change as you change the values of the parameters.

``{info, title = "R tip", collapsible = TRUE, ref.label = "rtip1"}
``

```


```{solution}
Let us see what happens when a higher force of infection is considered:

``{r, fig.height=8, fig.width=8}
higher_foi_params <- c(
    b = 1/(76*365),
  mu = 1/(76*365),
  beta1 = 0.3, beta2 = 0.1, beta3 = 0.5,
  sigma = 1/7,
  alpha = 1/50,
  gamma = 1/14,
  omega = 1/365
)
higher_foi_solution <- get_results(higher_foi_params, outs = c("I", "R"), 
                        times = c(25, 40, 100, 200, 300, 350, 500), raw = TRUE)
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, higher_foi_solution[,j,i], col=(3:4)[j-2], lwd=0.3)
legend('topleft', legend = c('Infected', "Recovered"), lty = 1, 
       col = c(3,4), inset = c(0.05, 0.05))
``

Comparing this with the plot produced before the task, we see that the peaks of recovered and infectious individuals have now increased, as expected. Also note how increasing the force of infection reduced the role of bimodality: the fact that more individuals get now infected during the first wave (around $t=40$), makes the chances of a second "wave" around time $t=300$ lower. 

What happens when a lower value of the recovery rate $\gamma$ is used?

``{r, fig.height=8, fig.width=8}
smaller_gamma_params <- c(
  b = 1/(60*365),
  mu = 1/(76*365),
  beta1 = 0.214, beta2 = 0.107, beta3 = 0.428,
   sigma = 1/7,
  alpha = 1/50,
  gamma = 1/20,
  omega = 1/365
)
smaller_gamma_solution <- get_results(smaller_gamma_params, outs = c("I", "R"), 
                                     times = c(25, 40, 100, 200, 300, 350, 500), raw = TRUE)
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, smaller_gamma_solution[,j,i], 
                                    col=(3:4)[j-2], lwd=0.3)
legend('topleft', legend = c('Infected', "Recovered"), lty = 1, 
       col = c(3,4), inset = c(0.05, 0.05))
``

As one expects, this causes the number of infectious individuals to increase. Also note that decreasing the recovery rate has increased the chances of having a second "wave" around $t=300$: there are now many more blue/green lines going up around $t=300$, compared to the plot produced before this task.
```

# 'wave0' - parameter ranges, targets and design points
In this section we set up the emulation task, defining the input parameter ranges, the calibration targets and all the data necessary to build the first wave of emulators. All these data are the same as the ones set in Workshop 1. Note that, for the sake of clarity, in this workshop we will adopt the word 'data' only when referring to the set of runs of the model that are used to train emulators. Real-world observations, that inform our choice of targets, will instead be referred to as 'observations'.

First of all, let us set the parameter ranges:

```{r}
ranges = list(
  b = c(1e-5, 1e-4), # birth rate
  mu = c(1e-5, 1e-4), # rate of death from other causes
  beta1 = c(0.2, 0.3), # infection rate at time t=0
  beta2 = c(0.1, 0.2), # infection rates at time t=100
  beta3 = c(0.3, 0.5), # infection rates at time t=270
  sigma = c(0.07, 0.21), # rate of becoming infectious after infection
  alpha = c(0.01, 0.025), # rate of death from the disease
  gamma = c(0.05, 0.08), # recovery rate
  omega = c(0.002, 0.004) # rate at which immunity is lost following recovery
)
```

We then turn to the targets we will match: the number of infectious individuals $I$ and the number of recovered individuals $R$ at times $t=25, 40, 100, 200, 200, 350$. For each of these outputs, we define a pair (val, sigma), where ‘val’ represents the measured value of the output and ‘sigma’ represents its standard deviation:

```{r}
targets <- list(
  I25 = list(val = 115.88, sigma = 5.79),
  I40 = list(val = 137.84, sigma = 6.89),
  I100 = list(val = 26.34, sigma = 1.317),
  I200 = list(val = 0.68, sigma = 0.034),
  I300 = list(val = 29.55, sigma = 1.48),
  I350 = list(val = 68.89, sigma = 3.44),
  R25 = list(val = 125.12, sigma = 6.26),
  R40 = list(val = 256.80, sigma = 12.84),
  R100 = list(val = 538.99, sigma = 26.95),
  R200 = list(val = 444.23, sigma = 22.21),
  R300 = list(val = 371.08, sigma = 15.85),
  R350 = list(val = 549.42, sigma = 27.47)
)
``` 
  
The 'sigmas' in our `targets` list represent the uncertainty we have about the observations. Note that in general we can also choose to include model uncertainty in the 'sigmas', to reflect how accurate we think our model is. For further discussion regarding model uncertainty, please see @bower2010galaxy, @vernon2018bayesian or @andrianakis2015bayesian.
  
```{info, title="More on how targets were set"}
Since our model is synthetic, we couldn't rely on observations to define our targets. Instead, we chose the parameter set 
``{r}
chosen_params <- list(b = 1/(76*365), mu = 1/(76*365), beta1 = 0.214, 
                      beta2 = 0.107, beta3 = 0.428, lambda = 1/7, alpha = 1/50, gamma = 1/14, omega = 1/365)
``

ran the deterministic model with it and used the relevant model outputs as the ‘val’ in `targets`. The ‘sigma’ components were chosen to be $5\%$ of the corresponding ‘val’.
``` 


For this workshop, we generate parameter sets using a [Latin Hypercube](https://en.wikipedia.org/wiki/Latin_hypercube_sampling) design. Through the function `maximinLHS` in the package `lhs`, we create two hypercube designs with 100 parameter sets and 50 parameter sets, one for the training set and one for the validation set.

```{r}
initial_lhs <- maximinLHS(100, 9)
validation_lhs <- lhs::randomLHS(50, 9)
```

Note that in `initial_LHS` and in `validation_lhs` each parameter is distributed on $[0,1]$. This is not exactly what we need, since each parameter has a different range. We therefore re-scale each component in `initial_LHS` and in `validation_lhs` multiplying it by the difference between the upper and lower bounds of the range of the corresponding parameter and then we add the lower bound for that parameter. In this way we obtain `initial_points` and `validation_points`, which contain parameter values in the correct ranges. 

```{r}
initial_points <- setNames(data.frame(t(apply(initial_lhs, 1, 
                                              function(x) x * purrr::map_dbl(ranges, diff) + 
                                              purrr::map_dbl(ranges, ~.[[1]])))), names(ranges))

validation_points <- setNames(data.frame(t(apply(validation_lhs, 1, 
                                                 function(x) x * purrr::map_dbl(ranges, diff) + 
                                                 purrr::map_dbl(ranges, ~.[[1]])))), names(ranges))
```

We then run the model for the parameter sets in `initial_points` and in `validation_points` through the `get_results` function, specifying that we are interested in the outputs for $I$ and $R$ at times at $t=25, 40, 100, 200, 300, 350, 450$.

```{r}
output_list <- list()
for (i in 1:nrow(initial_points)) {
  model_out <- get_results(unlist(initial_points[i,]), nreps = 50, outs = c("I", "R"), 
                           times = c(25, 40, 100, 200, 300, 350, 450))
  output_list[[i]] <- model_out
}
validation_list <- list()
for (i in 1:nrow(validation_points)) {
  model_out <- get_results(unlist(validation_points[i,]), nreps = 50, outs = c("I", "R"), 
                           times = c(25, 40, 100, 200, 300, 350, 450))
  validation_list[[i]] <- model_out
}
```

Note that `output_list` and `validation_list` are lists of length $5000$, since they have a row for each of the 50 repetitions of the 100 parameter sets. Finally, we bind all elements in `output_list` and all elements in `validation_list` to obtain two data frames `all_output` and `all_valid`.

```{r}
all_output <- data.frame(do.call('rbind', output_list))
all_valid <- data.frame(do.call('rbind', validation_list))
output_names <- c("I25", "I40", "I100", "I200", "I300", "I350", "I450",
                  "R25", "R40", "R100", "R200", "R300", "R350", "R450")
```

# Emulators 

In this section we will train two types of emulators. First we will work with stochastic emulators, which take into account the fact that running the model twice on a parameter set will produce different outputs. We will then introduce 
bimodal emulators, which deal with stochasticity in a more advanced way, actively accounting for bimodality in the outputs (if present).

We very briefly recap the general structure of a univariate emulator (see Workshop 1 for more details):

$$f(x) = g(x)^T \xi + u(x),$$

where $g(x)^T \xi$ is a regression term and $u(x)$ is a [weakly stationary process](https://en.wikipedia.org/wiki/Stationary_process#Weak_or_wide-sense_stationarity) with mean zero. 

The regression term, which mimics the global behaviour of the model output, is specified by a vector of functions of the parameters $g(x)$ which determine the shape and complexity of the regression 
<span class="abbr" title=""><abbr title="A hypersurface is a mathematical object that generalizes the concept of surface from the three-dimensional space to hyperspaces, i.e. spaces of dimension higher than three.
">hypersurface</abbr></span> we fit to the training data, and a vector of regression coefficients $\xi$. 

The [weakly stationary process](https://en.wikipedia.org/wiki/Stationary_process#Weak_or_wide-sense_stationarity) $u(x)$ (similar to a [Gaussian process](https://en.wikipedia.org/wiki/Gaussian_process)), accounts for the local deviations (or residuals) of the output from the regression hypersurface.

In this workshop, $u(x)$ is assumed to be a Gaussian process, with covariance structure given by 

$$\text{Cov}(u(x), u(x'))= \sigma^2  c(x,x^{\prime}) $$

where  $c$ is the square-exponential correlation function

$$c(x,x^{\prime}) :=  \exp\left(\frac{-\sum\limits_{i}(x_{i}-x_{i}^{\prime})^2}{\theta^2}\right)$$

where $x_i$ is the ith-component of the parameter set $x.$ The term $\sigma^2$ is the **emulator variance**, i.e the variance of $u(x)$, and reflects how far we expect the output to be from the regression hypersurface, while 
$\theta$ is the **correlation length** of the process, and determines how close two parameter sets must be in order for the corresponding residuals to be non-negligibly correlated. In the deterministic workshop, we said that in order to train an emulator, the `emulator_from_data` function first estimated values for $\sigma$ and $\theta$, thanks to the provided training data. It is important to note that these estimated values of $\sigma$ and $\theta$ were constant, i.e., they were independent of the pair $(x,x')$.

## Stochastic emulators

To train stochastic emulators we use the function `variance_emulator_from_data`, which requires the training data, the names of the outputs to emulate, and the ranges of the parameters:

```{r, fig.height=7, fig.width=7}
stoch_emulators <- variance_emulator_from_data(all_output, output_names, ranges)
```

The function `variance_emulator_from_data` returns two sets of emulators: one for the variance and one for the expectation of each model output. Behind the scenes, `variance_emulator_from_data` does the following:

- First, it calculates the variance of each model output of interest at each provided parameter set: this is possible since `all_output` contains several model runs at each parameter set. 

- Using the obtained variance data, it then trains an emulator for the variance of each of the outputs of interest. These emulators will be referred to as variance emulators and can be access typing `stoch_emulators$variance`.

- Finally, emulators for the mean of each output are built. These emulators will be referred to as mean emulators and can be accessed typing `stoch_emulators$expectation`. The main difference in the training of emulators between the stochastic and the deterministic case is that here, for each output, we use the variance emulator to inform our choice of $\sigma$: for each parameter set $x$, the variance emulator gives us an estimate of the variance of the model output at $x$. This means that the prior for $\sigma$ varies from parameter set to parameter set, and is therefore estimated more adequately across the input space, compared to the deterministic case, where $\sigma$ was constant.

Let's take a look at the two sets of emulators stored in `stoch_emulators`, starting with plots of active variables:

```{r, fig.height=7, fig.width=6}
plot_actives(stoch_emulators$variance)
plot_actives(stoch_emulators$expectation)
```

We see that $b$ and $\mu$ are inactive for almost all outputs in the variance emulators, even though they are active for some outputs in the mean emulators. Parameters $\beta_1$, $\beta_2$, $\sigma$, $\alpha$ are active for most or all outputs in the mean emulators. 

As in deterministic case, the `emulator_plot` can be used to visualise how emulators represent the output space. Of course, since we have two sets of emulators, we have several options in terms of plots. Since the default behaviour of `emulator_plot` is to plot the expectation, if we want to plot the expectation of the variance emulator for $I350$, we just need the following command:


```{r, fig.height=7, fig.width=9}
emulator_plot(stoch_emulators$variance$I350, params = c('sigma', 'alpha'))
```

where we chose to show the two parameters $\sigma$ and $\alpha$. 

To produce a similar plot for the expectation of the mean emulator for $I350$, we type:

```{r, fig.height=7, fig.width=9}
emulator_plot(stoch_emulators$expectation$I350, params = c('sigma', 'alpha'))
```

It is important to stress the following point: unlike in the deterministic case, here mean emulators do not have zero variance at  'known' points, i.e., at points in the training set. Let's verify this, by plotting the variance of the mean emulator for $I350$ in the $(\sigma,\alpha)$-plane, with all unshown parameters to be as in the first row of `all_output`:

```{r, fig.height=7, fig.width=9}
emulator_plot(stoch_emulators$expectation$I350, params = c('sigma', 'alpha'),
     fixed_vals = all_output[1, names(ranges)[-c(6,7)]], plot_type = 'var') +
   geom_point(data = all_output[1,], aes(x = sigma, y = alpha))
```

We see that the black point in the dark blue area, corresponding to the first point in `all_output`, does not have variance zero. This is because the mean emulator is trying to predict the 'true' mean at the point, but it has only been given a sample mean, which it cannot assume is equal to the 'true' mean. The emulator internally compensates for this incomplete information, resulting in the variance not being zero, even at points in the training set. This compensation also implies that we can work with different numbers of replicates at different parameter sets. This can be very useful: for example, if we know that a model is expensive to run in some part of the input space, we can do fewer replicates there and the emulators will take the disparity in the number of model runs into account.

Let's plot the trajectories for $I$ and $R$ at `chosen_params`, and let's overlay the predictions provided by the mean emulators, with their credible intervals. Note that to get the expectation and variance of the emulators at `chosen_df`, we use `get_exp` and `get_cov`, which require the point(s) to be passed as a dataframe. This is why we first create a dataframe `chosen_df` containing `chosen_params`.

```{r, fig.height=8, fig.width=8}
chosen_df <- data.frame(b = 1/(76*365),
                         mu = 1/(76*365),
                         beta1 = 0.214, beta2 = 0.107, beta3 = 0.428,
                         sigma = 1/7,
                         alpha = 1/50,
                         gamma = 1/14,
                         omega = 1/365
)
em_preds <- purrr::map_dbl(stoch_emulators$expectation, ~.$get_exp(chosen_df))
em_vars <- purrr::map_dbl(stoch_emulators$expectation, ~.$get_cov(chosen_df))
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, solution[,j,i], col=(3:4)[j-2], lwd=0.3)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[1:7])
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[8:14])
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[1:7]-3*sqrt(em_vars[1:7]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[1:7]+3*sqrt(em_vars[1:7]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[8:14]-3*sqrt(em_vars[8:14]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds[8:14]+3*sqrt(em_vars[8:14]), lty = 2)
legend('topleft', legend = c('Recovered', "Infected"), lty = 1, col = c(3,4), 
       inset = c(0.05, 0.05))
```

The plot shows us that we have a problem: since we're not explicitely taking the bimodality into account,
our emulators are not very useful at later times, when bimodality enters the picture. When we get to the branching point, the variance of the mean emulators is quite high, and the prediction is trying to match both modes, with the result that it matches neither of them well.

The take-away from this exploration, is that for models with stochasticity and no bimodality (or very low levels of
bimodality), the process described so far works well and therefore we can train emulators using the function `variance_emulator_from_data`. In the next subsection we will learn how to train emulators when bimodality is present. 

## Bimodal emulators

To train bimodal emulators we use the function `bimodal_emulator_from_data`, which requires the training data, the names of the outputs to emulate, and the ranges of the parameters:

```{r, fig.height=7, fig.width=7}
bimodal_emulators <- bimodal_emulator_from_data(all_output, output_names, ranges)
```

Behind the scenes, this function does the following:

- First it looks at the provided training data to identify which of the outputs are bimodal. 

- For the outputs where bimodality is found, the repetitions at each parameter set are clustered in two subsets, based on the mode they belong to.

- For outputs without bimodality, stochastic emulators are trained, as explained in the previous subsection. For outputs with bimodality, variance and mean emulators are trained for each of the two modes. To access the mean emulators for the first mode, we would type `bimodal_emulators$mode1$expectation`, while to access the variance emulators for the second mode we would type `bimodal_emulators$mode2$variance`. 

- Finally, an emulator for the proportion of points in each mode is also trained (this is a single emulator, as in the deterministic case). This emulator can be accessed by typing `bimodal_emulators$prop` and will be referred to as proportion emulator.

Let us now plot the expectation of the mean emulator for mode 1 of $R350$ and similarly for mode 2: 

```{r, fig.height=7, fig.width=9}
emulator_plot(bimodal_emulators$mode1$expectation$R350, params = c('alpha', 'sigma'))
emulator_plot(bimodal_emulators$mode2$expectation$R350, params = c('alpha', 'sigma'))
```

We immediately notice that there is large difference between the two plots, with mode 2 containing higher values than mode 1. This indicates that mode 1 is the one where the disease dies out.

It is also instructive to plot the expectation of the proportion emulator:

```{r, fig.height=7, fig.width=9}
emulator_plot(bimodal_emulators$prop, params = c('alpha', 'sigma'))
```

The plot shows that at points where alpha (rate of death from the disease) and sigma (rate of becoming infectious) are high, the first mode, where the disease dies out, dominates. However, from the plot it is also evident that there is always a
non-negligible risk of the disease dying out, since the proportion of points in the first mode never drops below $0.5$.

Let's conclude this section with a plot showing the predictions and relative uncertainties for mode 1 and mode 2 for the $I$ and $R$ outputs:
  
```{r, fig.height=7, fig.width=7}
em_preds1 <- purrr::map_dbl(bimodal_emulators$mode1$expectation, ~.$get_exp(chosen_df))
em_vars1 <- purrr::map_dbl(bimodal_emulators$mode1$expectation, ~.$get_cov(chosen_df))
em_preds2 <- purrr::map_dbl(bimodal_emulators$mode2$expectation, ~.$get_exp(chosen_df))
em_vars2 <- purrr::map_dbl(bimodal_emulators$mode2$expectation, ~.$get_cov(chosen_df))
plot(0:500, ylim=c(0,700), ty="n", xlab = "Time", ylab = "Number")
for(j in 3:4) for(i in 1:100) lines(0:500, solution[,j,i], col=(3:4)[j-2], lwd=0.3)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[1:7])
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[8:14])
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[1:7]-3*sqrt(em_vars1[1:7]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[1:7]+3*sqrt(em_vars1[1:7]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[8:14]-3*sqrt(em_vars1[8:14]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds1[8:14]+3*sqrt(em_vars1[8:14]), lty = 2)
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[1:7], col = 'red')
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[8:14], col = 'red')
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[1:7]-3*sqrt(em_vars1[1:7]), 
      lty = 2, col = 'red')
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[1:7]+3*sqrt(em_vars1[1:7]), 
      lty = 2, col = 'red')
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[8:14]-3*sqrt(em_vars1[8:14]), 
      lty = 2, col = 'red')
lines(c(25, 40, 100, 200, 300, 350, 450), em_preds2[8:14]+3*sqrt(em_vars1[8:14]), 
      lty = 2, col = 'red')
legend('topleft', legend = c('Recovered', "Infected"), lty = 1, col = c(3,4), 
       inset = c(0.05, 0.05))
```

Here we clearly see that `bimodal_emulators_from_data` captured the bimodal structure of the outputs, producing emulators that are more appropriate than the stochastic emulators.

```{task}
Confirm that mode 1 is where the disease dies out by comparing the plots of the expectation of the mean emulator for $I300$ for both modes.
```


```{solution}
We use `emulator_plot` to produce the suggested plots:

``{r, fig.height=8, fig.width=8}
emulator_plot(bimodal_emulators$mode1$expectation$I300, params = c('alpha', 'sigma'))
emulator_plot(bimodal_emulators$mode2$expectation$I300, params = c('alpha', 'sigma'))
``

The values in the plot for mode 1 are clearly lower than those for mode 2: this reflects the fact that mode 2 experiences a second wave around $t=300$, while in mode 1 the disease dies out after the first wave (around $t=40$). 
```


# Implausibility 

Since we are now in a bimodal setting, we want to regard a point as non-implausible for a given target if it is valid with respect to either mode. This is the default behaviour of the package, when dealing with bimodal emulators. 

```{info, title="Remind me of how the implausibility measure is defined"}
We quickly review the definition of implausibility measure. For a given model output and a given target, the implausibility measures the difference between the emulator output and the target, taking into account all sources of uncertainty. For a parameter set $x$, the general form for the implausibility $\text{Imp}(x)$ is

$$\text{Imp}(x) = \frac{|f(x)-z|}{\sqrt{V_0 + V_c(x)+V_s+V_m}},$$

where $f(x)$ is the emulator output, $z$ the target, and the terms in the denominator refer to various forms of uncertainty. In particular

- $V_0$ is the variance associated with the observation uncertainty;
- $V_c(x)$ refers to the uncertainty one introduces when using the emulator output instead of the model output itself;
- $V_s$ is the ensemble variability and represents the stochastic nature of the model;
- $V_m$ is the model discrepancy, accounting for possible mismatches between the model and reality.

Since in this case study we want to emulate our model, without reference to a real-life analogue, the model represents the reality perfectly. For this reason we have $V_m=0$. 

A very large value of $\text{Imp}(x)$ means that we can be confident that the parameter set $x$ does not provide a good match to the observed data, even factoring in the additional uncertainty that comes with the use of emulators.
```

For a given output and a given point, the implausibility for mode 1 and the implausibility for mode 2 are calculated, and the minimum of them is taken. The maximum (or second-maximum, third-maximum etc) of this collection of minimised implausibilities is then selected, depending on the user choice. For example, to plot the maximum of these minimised implausibilities, we set `plot_type` to `nimp`:

```{r, fig.height=7, fig.width=9}
emulator_plot(subset_emulators(bimodal_emulators, output_names[-c(7,14)]), plot_type = 'nimp', 
              targets = targets, params = c('alpha', 'sigma'))
```

Here we used the function `subset_emulators` to remove the emulators for the outputs at $t=450$, for which we did not set targets (to keep the symmetry with the deterministic case).

```{task}
Use the argument `fixed_vals` to set the parameters that are not shown in the plot to be as in `chosen_params`. Verify that the implausibility at `chosen_params` is below 3.
```

```{solution}
We set `fixed_vals` to `chosen_params[!names(chosen_params) %in% c('alpha', 'sigma')]`, plot the maximum implausibility and add a point corresponding to the values of $\sigma$ and $alpha$ in `chosen_params`:

``{r fig.width = 7, fig.height = 6}
emulator_plot(subset_emulators(bimodal_emulators, output_names[-c(7,14)]), plot_type = 'nimp', targets = targets,
              params = c('alpha', 'sigma'),
              fixed_vals = chosen_params[!names(chosen_params) %in% c('alpha', 'sigma')], 
              cb=T) +geom_point(aes(x=1/7, y=1/50), size=3)
``
The plot shows what we expected: when $\sigma$ and $\alpha$ are equal to their values in `chosen_params`, the implausibility measure is below the threshold $3$ (cf. black point in the box). 
```

```{task}
Set the argument `plot_type` to `imp` to produce implausibility plots for each output, for mode 1 and mode 2. In between modes, which implausibility plots stay the same and which change? Why?
```

```{solution}
Setting `plot_type='imp'` in `emulator_plot` and passing it either `subset_emulators(bimodal_emulators, output_names[-c(7,14)])$mode1` or `subset_emulators(bimodal_emulators, output_names[-c(7,14)])$mode2`, we get:

``{r fig.width = 7, fig.height = 6}
emulator_plot(subset_emulators(bimodal_emulators, output_names[-c(7,14)])$mode1, plot_type = 'imp', targets = targets,
              params = c('alpha', 'sigma'))
emulator_plot(subset_emulators(bimodal_emulators, output_names[-c(7,14)])$mode2, plot_type = 'imp', targets = targets,
               params = c('alpha', 'sigma'))
``
The implausibility plots are the same between modes for early times ($t=25,40,100$) and quite different between modes for later outputs. This makes sense, since bimodality, which enters the picture after the first wave, does not play a role in earlier times. 
```

# Emulator diagnostics

The function `validation_diagnostics` can be used as in the deterministic case, to get three diagnostics for each emulated output.

```{r,  fig.height=8, fig.width=8}
vd <- validation_diagnostics(subset_emulators(bimodal_emulators, output_names[-c(7,14)]), 
                       targets, all_valid, plt=TRUE)
```

```{info, title="Remind me of what each dagnostics means"}
The first plot shows the emulator outputs plotted against the model outputs. In particular, the emulator expectation is plotted against the model output for each validation point, providing the dots in the graph. The emulator uncertainty at each validation point is shown in the form of a vertical interval that goes from $3\sigma$ below to $3\sigma$ above the emulator expectation, where $\sigma$ is the emulator variance at the considered point.  An 'ideal' emulator would exactly reproduce the model results: this behaviour is represented by the green line $f(x)=E[f(x)]$ (this is a diagonal line, visible here only in the bottom left and top right corners). Any parameter set whose emulated prediction lies more than $3\sigma$ away from the model output is highlighted in red. Note that we do not need to have no red points for the test to be passed: since we are plotting $3\sigma$ bounds, statistically speaking it is ok to have up to $5\%$ of validation points in red (see [Pukelsheim's $3\sigma$ rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)).

The second column compares the emulator implausibility to the equivalent model implausibility (i.e. the implausibility calculated replacing the emulator output with the model output). There are three cases to consider:

- The emulator and model both classify a set as implausible or non-implausible (bottom-left and top-right quadrants). This is fine. Both are giving the same classification for the parameter set. 

- The emulator classifies a set as non-implausible, while the model rules it out (top-left quadrant): this is also fine. The emulator should not be expected to shrink the parameter space as much as the model does, at least not on a single wave. Parameter sets classified in this way will survive this wave, but may be removed on subsequent waves as the emulators grow more accurate on a reduced parameter space.

- The emulator rules out a set, but the model does not (bottom-right quadrant): these are the problem sets, suggesting that the emulator is ruling out parts of the parameter space that it should not be ruling out.

As for the first test, we should be alarmed only if we spot a systematic problem, with $5\%$ or more of the points in the bottom-right quadrant. 

Finally, the third column gives the standardised errors of the emulator outputs in light of the model output: for each validation point, the difference between the emulator output and the model output is calculated, and then divided by the standard deviation $\sigma$ of the emulator at the point. The general rule is that we want our standardised errors to be somewhat normally distributed around $0$, with $95\%$ of the probability mass between $-2$ and $2$. When looking at the standard errors plot, we should ask ourselves at least the following questions:

- Is more than $5\%$ of the probability mass outside the interval $[-2,2]$? If the answer is yes, this means that, even factoring in all the uncertainties in the emulator and in the observed data, the emulator output is too often far from the model output. 

- Is $95\%$ of the probability mass concentrated in a considerably smaller interval than $[-2,2]$ (say, for example, $[-0.5,0.5]$)? For this to happen, the emulator uncertainty must be quite large. In such case the emulator, being extremely cautious, will cut out a small part of the parameter space and we will end up needing many more waves of history matching than are necessary, or, even worse, we just won't be able to reduce the non-implausible parameter space.

- Is the histogram skewing significantly in one direction or the other? If this is the case, the emulator tends to either overestimate or underestimate the model output.
``` 

You may have noticed that we seem to have more points plotted than we have validation points on the left column. This is because we do diagnostics on each mode for each output, i.e. we compare the predictions of the mean emulators for mode 1 and mode 2 with the model output values, which are also clustered in two subsets, due to bimodality. In fact, for $I350$ you can actually see the mode separation in the left plot (some runs are concentrated around zero and the rest are all above 15). Similarly, for $I200$ you can distinguish the two modes by the step change in uncertainty.

As in deterministic case, we can enlarge the $\sigma$ values to obtain more conservative emulators, if needed. Based on the diagnostics above, all emulators perform quite well. We will only modify the $\sigma$ value for the mean emulators for $R100$ (which misclassified a point in the middle column), in both modes:

```{r}
bimodal_emulators$mode1$expectation$R100 <- bimodal_emulators$mode1$expectation$R100$mult_sigma(3)
bimodal_emulators$mode2$expectation$R100 <- bimodal_emulators$mode2$expectation$R100$mult_sigma(3)
```

The new diagnostics for $R100$ are fine:

```{r,  fig.height=8, fig.width=8}
vd <- validation_diagnostics(subset_emulators(bimodal_emulators, output_names[c(10)]), 
                       targets[c(9)], all_valid, plt=TRUE)
```

# Proposing new points

To generate a set of non-implausible points, based on the trained emulators, we use the function `generate_new_runs`, exactly as in the deterministic case: 

```{r,cache=F}
new_points <- generate_new_runs(subset_emulators(bimodal_emulators, output_names[-c(7,14)]), 
                                200, targets, nth=1)
```

We can visualise the non-implausible space at the end of this first wave using `plot_wrap`:

```{r,  fig.height=8, fig.width=8}
plot_wrap(new_points, ranges)
```

# Second wave

```{r}
min_val <- list()
max_val <- list()
new_ranges <- list()
for (i in 1:length(ranges)) {
    par <- names(ranges)[[i]]
    min_val[[par]] <- max(min(new_points[,par])-0.05*diff(range(new_points[,par])), 
                      ranges[[par]][1])
    max_val[[par]] <- min(max(new_points[,par])+0.05*diff(range(new_points[,par])),
                      ranges[[par]][2])
    new_ranges[[par]] <- c(min_val[[par]], max_val[[par]])
}
```

```{r}
t_sample <- sample(1:nrow(new_points), 100)
new_training <- new_points[t_sample,]
new_validation <- new_points[-t_sample,]

new_output_list <- list()
for (i in 1:nrow(new_training)) {
  new_model_out <- get_results(unlist(new_training[i,]), nreps = 50, outs = c("I", "R"), 
                           times = c(25, 40, 100, 200, 300, 350, 450))
  new_output_list[[i]] <- new_model_out
}
new_validation_list <- list()
for (i in 1:nrow(new_validation)) {
  new_model_out <- get_results(unlist(new_validation[i,]), nreps = 50, outs = c("I", "R"), 
                           times = c(25, 40, 100, 200, 300, 350, 450))
  validation_list[[i]] <- new_model_out
}
new_all_output <-  data.frame(do.call('rbind',new_output_list))
```

```{r}
new_bimodal_emulators <- bimodal_emulator_from_data(new_all_output, output_names, new_ranges)

```

```{r, fig.height=8, fig.width=8}
vd <- validation_diagnostics(subset_emulators(new_bimodal_emulators, output_names[-c(7,14)]), targets, all_valid, plt=TRUE)
```

```{r, cache=F}
new_bimodal_emulators$mode1$expectation$R100 <- new_bimodal_emulators$mode1$expectation$R100$mult_sigma(3)
new_bimodal_emulators$mode2$expectation$R100 <- new_bimodal_emulators$mode2$expectation$R100$mult_sigma(3)
new_bimodal_emulators$mode1$expectation$R200 <- new_bimodal_emulators$mode1$expectation$R200$mult_sigma(2)
new_bimodal_emulators$mode2$expectation$R200 <- new_bimodal_emulators$mode2$expectation$R200$mult_sigma(2)
```

```{r, fig.height=8, fig.width=8,cache=F}
vd <- validation_diagnostics(subset_emulators(new_bimodal_emulators, output_names[-c(7,14)]), targets, all_valid, plt=TRUE)
```

```{r,cache=F}
new_new_points <- generate_new_runs(subset_emulators(c(new_bimodal_emulators, bimodal_emulators),
                                    output_names[-c(7,14)]), 200, targets, nth=1)
```

```{r,  fig.height=8, fig.width=8,cache=F}
plot_wrap(new_new_points, ranges)
```

```{r,  fig.height=8, fig.width=8,cache=F}
wave_points(list(initial_points, new_points, new_new_points), input_names = names(ranges))
```

```{r,  fig.height=8, fig.width=8,cache=F}
new_new_output_list <- list()
for (i in 1:nrow(new_new_points)) {
  new_new_model_out <- get_results(unlist(new_new_points[i,]), nreps = 50, outs = c("I", "R"), 
                           times = c(25, 40, 100, 200, 300, 350, 450))
  new_new_output_list[[i]] <- new_new_model_out
}
new_new_all_output <-  data.frame(do.call('rbind',new_new_output_list))
all_points <- list(all_output, new_all_output, new_new_all_output)
simulator_plot(all_points, targets)
```
